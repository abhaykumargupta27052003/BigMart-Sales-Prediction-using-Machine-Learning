import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import warnings
warnings.filterwarnings('ignore')
data = pd.read_csv('/Users/abhaykumargupta')
#d_test = pd.read_csv('/datasets_9961_14084_Test.csv')
data.head()
print(data.shape)
print(data.columns)
data.info()
data.isna().sum()
data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)
data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)
plt.figure(figsize=(10,5))
sns.boxplot(data['Item_Outlet_Sales'])
plt.title("Outlier Detection in Sales")
plt.show()
le = LabelEncoder()
for col in ['Item_Identifier','Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Size','Outlet_Location_Type','Outlet_Type']:
    data[col] = le.fit_transform(data[col])
scaler = StandardScaler()
scaled_cols = ['Item_Weight','Item_Visibility','Item_MRP']
data[scaled_cols] = scaler.fit_transform(data[scaled_cols])
plt.figure(figsize=(10,8))
sns.heatmap(data.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()
X = data.drop('Item_Outlet_Sales', axis=1)
y = data['Item_Outlet_Sales']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(x_train, y_train)
y_pred = lr.predict(x_test)

print("Linear Regression R2 Score:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

x_train_p, x_test_p, y_train_p, y_test_p = train_test_split(X_poly, y, test_size=0.2, random_state=42)

lr_poly = LinearRegression()
lr_poly.fit(x_train_p, y_train_p)
y_pred_p = lr_poly.predict(x_test_p)

print("Polynomial Regression R2 Score:", r2_score(y_test_p, y_pred_p))
from sklearn.linear_model import LinearRegression

mlr = LinearRegression()
mlr.fit(x_train, y_train)
y_pred = mlr.predict(x_test)

print("MLR R2 Score:", r2_score(y_test, y_pred))
from sklearn.tree import DecisionTreeRegressor

dt = DecisionTreeRegressor(max_depth=8, random_state=42)
dt.fit(x_train, y_train)
y_pred = dt.predict(x_test)

print("Decision Tree R2 Score:", r2_score(y_test, y_pred))
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(x_train, y_train)
y_pred = rf.predict(x_test)

print("Random Forest R2 Score:", r2_score(y_test, y_pred))
from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(x_train, y_train)
y_pred = knn.predict(x_test)

print("KNN R2 Score:", r2_score(y_test, y_pred))
data.hist(figsize=(10,10))
from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor()
gbr.fit(x_train, y_train)
y_pred = gbr.predict(x_test)

print("Gradient Boosting R2 Score:", r2_score(y_test, y_pred))
models = {
    "Linear Regression": lr,
    "Decision Tree": dt,
    "Random Forest": rf,
    "KNN": knn,
    "Gradient Boosting": gbr
}

results = []

for name, model in models.items():
    pred = model.predict(x_test)
    results.append([name,
                    r2_score(y_test,pred),
                    mean_absolute_error(y_test,pred),
                    np.sqrt(mean_squared_error(y_test,pred))])

result_df = pd.DataFrame(results, columns=["Model", "R2 Score", "MAE", "RMSE"])
print(result_df)
plt.figure(figsize=(10,6))
sns.barplot(x=result_df['Model'], y=result_df['R2 Score'], palette='coolwarm')
plt.title("Model Comparison (R2 Score)")
plt.xlabel("Models")
plt.ylabel("R2 Score")
plt.show()
plt.figure(figsize=(12,6))
data[['Item_Weight','Item_Visibility','Item_MRP','Item_Outlet_Sales']].hist(bins=20, figsize=(12,6), grid=False)
plt.suptitle("Histograms of Numerical Features")
plt.show()
plt.figure(figsize=(6,6))
data['Outlet_Type'].value_counts().plot(kind='pie', autopct='%1.1f%%', shadow=True)
plt.title("Outlet Type Distribution")
plt.ylabel("")
plt.show()
